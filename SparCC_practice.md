#   SparCC 

#### SparCC [source depository](https://bitbucket.org/yonatanf/sparcc)is a python module for computing correlations
in compositional data (16S, metagenomics, etc').

# Installation to Beacon server
* Download the source code from [download site](https://bitbucket.org/yonatanf/sparcc/get/05f4d3f31d77.zip) to my directory
```
cd /lustre/medusa/fliu21/SparCC
wget https://bitbucket.org/yonatanf/sparcc/get/05f4d3f31d77.zip
```
Then **unzip** the directory and **change file name** to SparCC\_bitbucket

```
unzip 05f4d3f31d77.zip
mv yonatanf-sparcc-05f4d3f31d77/ SparCC_bitbucket
rm 05f4d3f31d77.zip
```
* I have installed Panda package in my ``anaconda2/bin`` directory, so I will set up the PATH to this 

```
expo
rt PATH=/lustre/medusa/fliu21/anaconda2/bin:$PATH
```
* As python has already installed on beacon server, I just load the environment by
```
module load python/3.6.1
```
* Now type in ``python SparCC.py -h`` inside of ``SparCC_bitbucket`` directory, you will see below manual

```
Example: python SparCC.py example/fake_data.txt -i 20 --cor_file=example/basis_corr/cor_mat_sparcc.out

Options:
  -h, --help            show this help message and exit
  -c COR_FILE, --cor_file=COR_FILE
                        File to which correlation matrix will be written.
  -v COV_FILE, --cov_file=COV_FILE
                        File to which covariance matrix will be written.
  -a ALGO, --algo=ALGO  Name of algorithm used to compute correlations (SparCC
                        (default) | pearson | spearman | kendall)
  -i ITER, --iter=ITER  Number of inference iterations to average over (20
                        default).
  -x XITER, --xiter=XITER
                        Number of exclusion iterations to remove strongly
                        correlated pairs (10 default).
  -t TH, --thershold=TH
                        Correlation strength exclusion threshold (0.1
                        default).

```
Look into the example file, the input out table is formated with **rows being OTUs** from 1 to 50; **columns are sample** names from 1 to 200 samples

## SparCC at class level using phyloseq-based OTU cluster data (including .shared and .cons.taxonomy)

* Prepare table format in R using phyloseq package
  1. Generate class level phyloseq using all samples
  2. Subset samples to include only Ag rhizosphere samples
  3. Filter off classes that has maximum abundance smaller than 20
  4. transform absolute abundance to relative abundance.
  5. Comebine tax\_table and otu\_table
  6. Write out ``r_filter_Ag_Rhi_otu_and_tax_table.csv`` table to local
  
* Upload table to beacon server /lustre/medusa/fliu21/SparCC directory
* change csv file to txt file using 

```
sed 's/,/\t/g' r_filter_Ag_Rhi_otu_and_tax_table.csv > r_filter_Ag_Rhi_otu_and_tax_table.txt
```

* Inside of ``AgRhi_SparCC `` directory, create ``basis_corr`` and ``pvals`` folder
* Go back to ``/lustre/medusa/fliu21/SparCC`` directory

* RUN SparCC.py command

```
python SparCC.py AgRhi_SparCC/r_filter_Ag_Rhi_otu_and_tax_table.txt  -i 20 --cor_file=AgRhi_SparCC/basis_corr/AgRhi_cor_sparcc.txt -a SparCC
```
   1. Here -i means the number of inference iterations to avaerage over. -a means the algrithm for calculate correaction, which include SparCC, Peason, Spearman and Kendall.
   
* Now make shuffled datasets for calculating p value using ``MakeBootstraps.py`` function.

   1. Here are the help file of ``MakeBootstraps`` (documentation)
   
```
   Usage: Make n simulated datasets used to get pseudo p-values.
Simulated datasets are generated by assigning each OTU in each sample an abundance that is randomly drawn (w. replacement) from the abundances of the OTU in all samples.
Simulated datasets are either written out as txt files. 

Usage:   python MakeBootstraps.py counts_file [options]
Example: python MakeBootstraps.py example/fake_data.txt -n 5 -t permutation_#.txt -p example/pvals/

Options:
  -h, --help            show this help message and exit
  -n N                  Number of simulated datasets to create (100 default).
  -t PERM_TEMPLATE, --template=PERM_TEMPLATE
                        The template for the permuted data file names. Should
                        not include the path, which is specified using the -p
                        option. The iteration number is indicated with a "#".
                        For example: 'permuted/counts.permuted_#.txt'If not
                        provided a '.permuted_#.txt' suffix will be added to
                        the counts file name.
  -p OUTPATH, --path=OUTPATH
                        The path to which permuted data will be written. If
                        not provided files will be written to the cwd.
```

2. My code
   
* I created a subfolder ``bootstrap_simulation`` inside of pval folder to hold the simulated dataset

* Run command 
     
     ```
     python MakeBootstraps.py  AgRhi_SparCC/r_filter_Ag_Rhi_otu_and_tax_table.txt -n 200  
     --template=AgRhi_otu_count_permutation#.txt --path=AgRhi_SparCC/pvals/bootstrap_simulation/
     ```
     
* Part of the simulated output file by ``MakeBootstraps.py``
     
     ```
     AgRhi_otu_count_permutation0.txt    
     AgRhi_otu_count_permutation160.txt  
     AgRhi_otu_count_permutation40.txt
     AgRhi_otu_count_permutation100.txt  
     AgRhi_otu_count_permutation161.txt  
     AgRhi_otu_count_permutation41.txt
     AgRhi_otu_count_permutation101.txt  
     AgRhi_otu_count_permutation162.txt 
     ```
     
* Calculate p\_value using shuffled dataset with exactly the same parameter set up when calculate the former data set. Name all the output files consistently, numbered sequentially, and with a '.txt' extension.
   
   
  **NOTE** If I only calculate p\_value using one shuffled dataset, the command will like below
   
   ```
   python SparCC.py AgRhi_SparCC/pvals/bootstrap_simulation/AgRhi_otu_count_permutation0.txt -i 20 --cor_file=AgRhi_SparCC/pvals/bootstrap_corr/AgRhi_bootstrap_permutation0_corr.txt -a SparCC
   
   ```
   
  **As I have 200 bootstrap permutations, I will write a for loop to do this work**
   
   1. Creat a script
   ``nano calculate_SparCC_on_simulated_dataset.sge``
   
   ```
   for ((i=0;i<=199;i++))
   do
     echo $i
     python SparCC.py AgRhi_SparCC/pvals/bootstrap_simulation/AgRhi_otu_count_permutation$i.txt -i 20 --cor_file=AgRhi_SparCC/pvals/bootstrap_corr/AgRhi_bootstrap_permutation$i_corr.txt -a SparCC
     
   done
   ```
   **NOTE** The above for loop did not do the work for 200 samples. It just generated one file named ``AgRhi_bootstrap_permutation``
   
 Â    * Told by Miriam, the variable $i need double quoted when named together with underscore. Because this will separate the content between`` _``. So always double quote when name a file with variable.
     * Function double cite - echo (echo path/filename\_"$i") 
   
   
   
   2. Change script to excutable
   ``chmod u+x calculate_SparCC_on_simulated_dataset.sge``
   
   3. RUN ``calculate_SparCC_on_simulated_dataset.sge``script
   
   ```
   sh calculate_SparCC_on_simulated_dataset.sge
   ```
   4. It will take a while to finish SparCC calculation using 200 simulated datasets.
   






















